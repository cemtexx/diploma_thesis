{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"S-NeU5xKX8zP"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","import os\n","import random\n","import numpy as np\n","import pickle\n","import cv2\n","import pickle\n","\n","from skimage.io import imread, imshow\n","import matplotlib.pyplot as plt\n","\n","# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# define variables\n","seed = 1\n","\n","IMG_WIDTH = 512\n","IMG_HEIGHT = 512\n","IMG_CHANNELS = 3\n","\n","PLOT_SIZE = 20\n","VERSION = 'version_name'\n","VALIDATION_SPLIT = 0.15\n","LR = 0.001\n","FIRST_CONVS = 16\n","\n","LOCAL_FILTER = 5\n","MINIMUM_DISTANCE = 3\n","TM = 0.2\n","\n","# define paths\n","TRAIN_DATA_IMAGES_PATH = '/content/drive/MyDrive/unet/train_data_images/'\n","TEST_DATA_IMAGES_PATH = '/content/drive/MyDrive/unet/test_data_images/'\n","PICKLE_PATH = '/content/drive/MyDrive/unet/images_data.pickle'\n","\n","SAVE_MODEL_PATH = '/content/drive/MyDrive/unet/models' + VERSION + '.h5'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aI4Nqk3aG0-r"},"outputs":[],"source":["# DEFINE FUNCTIONS\n","# define function for draw gradiends to a masks\n","def mark_gradient(x, y, image, radius):\n","    radius = 5\n","    for i in range(1, radius*2+1):\n","        for j in range(1, radius*2+1):\n","            distance = np.sqrt((i-radius)**2 + (j-radius)**2)\n","            if distance < radius:\n","                # linearni interpolace\n","                gray = int(-(255/radius)*distance + 255)\n","\n","                # nelinearni interpolace https://www.desmos.com/calculator/fz5tqkzosn\n","                #nonlinear_parameter = 3 # the higher the more nonlinear\n","                #gray = -255*(distance/radius)**(1/nonlinear_parameter) + 255\n","\n","                try:\n","                    image[i+x-radius, j+y-radius] = gray\n","                except IndexError:\n","                    pass\n","    return image\n","\n","# define function for augmentation\n","# some functions inspired by: https://stackoverflow.com/questions/22937589/how-to-add-noise-gaussian-salt-and-pepper-etc-to-image-in-python-with-opencv/30609854#30609854\n","def random_noise(input_image):\n","    case = random.randint(1, 4)\n","\n","    if case == 1: # gaussian noise\n","        row,col,ch= input_image.shape\n","        mean = 0\n","        sigma = 0.5\n","        gauss = np.random.normal(mean,sigma,(row,col,ch))\n","        gauss = gauss.reshape((row,col,ch)).astype('uint8')\n","        noise_image = input_image + gauss\n","\n","    elif case == 2: # salt and pepper\n","        row,col,ch = input_image.shape\n","        s_vs_p = 0.5\n","        amount = 0.03\n","        noise_image = np.copy(input_image)\n","\n","        # Salt mode\n","        num_salt = np.ceil(amount * input_image.size * s_vs_p)\n","        coords = [np.random.randint(0, i - 1, int(num_salt))\n","                for i in input_image.shape]\n","        noise_image[coords] = 1\n","\n","        # Pepper mode\n","        num_pepper = np.ceil(amount* input_image.size * (1. - s_vs_p))\n","        coords = [np.random.randint(0, i - 1, int(num_pepper))\n","                for i in input_image.shape]\n","        noise_image[coords] = 0\n","\n","    elif case == 3: # speckle\n","        row,col,ch= input_image.shape\n","        mean = 0\n","        sigma = 0.5\n","        gauss = np.random.normal(mean,sigma,input_image.size)\n","        gauss = gauss.reshape((row,col,ch)).astype('uint8')\n","        noise_image = input_image + input_image * gauss\n","\n","    else:\n","        noise_image = input_image\n","\n","    return noise_image\n","\n","# define function for chceck if there is any other scale nearby\n","def no_neighbor(point, points, minimum_distance):\n","    if len(points) == 0:\n","        return True\n","\n","    for loop_point in points:\n","        distance = np.sqrt((point[0] - loop_point[0])**2 + (point[1] - loop_point[1])**2)\n","        if distance < minimum_distance:\n","            return False\n","\n","    return True\n","\n","# define function for counting scales\n","def counterpoint(raw_image, local_filter, minimum_distance, tm, centers_to=None):\n","    image = raw_image*(255/raw_image.max())\n","    image = image.astype(int)\n","\n","    if (local_filter % 2) == 0:\n","        local_filter += 1\n","\n","    H = image.shape[0]\n","    W = image.shape[1]\n","\n","    # MAX FILTER\n","    add_black = int(local_filter/2)\n","    padding = np.pad(np.squeeze(image), pad_width=add_black, mode='constant', constant_values=0)\n","    padding = np.expand_dims(padding, axis=2)\n","    max_filter = np.zeros((H, W, 1), np.uint8)\n","    for x in range(0, H):\n","        for y in range(0, W):\n","            im_filter = padding[x:x+local_filter, y:y+local_filter]\n","            max_filter[x][y] = im_filter.max()\n","\n","    B1 = np.zeros((H, W, 1), np.uint8)\n","    for x in range(0, H):\n","        for y in range(0, W):\n","            if max_filter[x][y] == image[x][y]:\n","                B1[x][y] = 255\n","            else:\n","                B1[x][y] = 0\n","\n","    # MASK OMEGA\n","    omega = np.zeros((H, W, 1), np.uint8)\n","    for x in range(0, H):\n","        for y in range(0, W):\n","            if image[x][y] == 0:\n","                omega[x][y] = 255\n","            else:\n","                omega[x][y] = 0\n","\n","    # EROSION\n","    kernel = np.ones((local_filter, local_filter), np.uint8)\n","    erosion = cv2.erode(omega, kernel, iterations = 1)\n","\n","    # XOR OF EROSION MASK AND MASK1\n","    B_omega = np.zeros((H, W, 1), np.uint8)\n","    for x in range(0, H):\n","        for y in range(0, W):\n","            if B1[x][y] == erosion[x][y]:\n","                B_omega[x][y] = 0\n","            else:\n","                B_omega[x][y] = 255\n","\n","\n","    # MASK1\n","    centroid_map = np.zeros((H, W, 1), np.uint8)\n","    centers = []\n","    for x in range(0, H):\n","        for y in range(0, W):\n","            if B_omega[x][y] == 255 and image[x][y] >= int(255*tm):\n","                centroid_map[x][y] = 255\n","                if no_neighbor((x, y), centers, MINIMUM_DISTANCE):\n","                    centers.append((x, y))\n","            else:\n","                centroid_map[x][y] = 0\n","\n","    image = image/255\n","\n","    # devide into class1 (left scales) and class2 (right scales)\n","    group1 = []\n","    group2 = []\n","\n","    most_left = (W, H)\n","    for point in centers:\n","        if point[1] < most_left[1]:\n","            most_left = point\n","\n","    measured_point = most_left\n","    distances = []\n","    nearest_point = (0, 0) # x, y\n","    \n","    centers_to_devide = centers[:]\n","    centers_to_devide.remove(measured_point)\n","    group1.append(measured_point)\n","\n","    # filter close points\n","    while True:\n","        shortest_dist = H\n","        for point in centers_to_devide:\n","            distance = np.sqrt((point[0] - measured_point[0])**2 + (point[1] - measured_point[1])**2)\n","            if distance < shortest_dist:\n","                nearest_point = point\n","                shortest_dist = distance\n","\n","        measured_point = nearest_point\n","\n","        if len(distances) == 0:\n","            pass\n","        elif shortest_dist > 2*(sum(distances)/len(distances)):\n","            group2 = centers_to_devide[:]\n","            break\n","\n","        distances.append(shortest_dist)\n","        centers_to_devide.remove(measured_point)\n","        group1.append(measured_point)\n","\n","    # decide which group is upper -> class2 (right scales) and which is more down -> class1 (left scales)\n","    sum_y = 0\n","    for point in group1:\n","        sum_y += point[1]\n","    group1_average_y = sum_y\n","\n","    sum_y = 0\n","    for point in group2:\n","        sum_y += point[1]\n","    group2_average_y = sum_y\n","\n","    if group1_average_y > group2_average_y:\n","        class1 = group1[:]\n","        class2 = group2[:]\n","    else:\n","        class1 = group2[:]\n","        class2 = group1[:]\n","\n","\n","    # draw results into images\n","    final_image = np.append(image, image, axis=2)\n","    final_image = np.append(final_image, image, axis=2)\n","    \n","    for center in class1:\n","        final_image = cv2.circle(final_image, (center[1],center[0]), 0, (0,0,255), 4)\n","    for center in class2:\n","        final_image = cv2.circle(final_image, (center[1],center[0]), 0, (255,0,0), 4)\n","    \n","    if centers_to is not None:\n","        centers_original = centers_to.copy()\n","        for center in class1:\n","            centers_original = cv2.circle(centers_original, (center[1],center[0]), 0, (0,0,255), 4)\n","        for center in class2:\n","            centers_original = cv2.circle(centers_original, (center[1],center[0]), 0, (255,0,0), 4)\n","\n","    else:\n","        centers_original = centers_to.copy()\n","\n","    return [centers, final_image, centers_original]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43LX7FGXpGKn"},"outputs":[],"source":["# LOAD TEST AND TRAIN IMAGES\n","# preparing data and unet model architecture inspired by: https://github.com/bnsreenu/python_for_microscopists/blob/master/076-077-078-Unet_nuclei_tutorial.py\n","try:\n","    pickle_in = open(PICKLE_PATH, 'rb')\n","    gradients  = pickle.load(pickle_in)\n","    pickle_in.close()    \n","\n","    print('labels for', len(gradients), 'images found')\n","\n","except FileNotFoundError:\n","    print('no .pickle file in path: ', PICKLE_PATH)\n","\n","train_ids = []\n","test_ids = []\n","\n","for file_name in os.listdir(TRAIN_DATA_IMAGES_PATH):\n","    if file_name[-4:] == '.png' and file_name in gradients:\n","        train_ids.append(file_name)\n","\n","for file_name in os.listdir(TEST_DATA_IMAGES_PATH):\n","    if file_name[-4:] == '.png':\n","        test_ids.append(file_name)\n","\n","print('train images:', len(train_ids))\n","print('test images:', len(test_ids))\n","\n","images = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n","masks = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n","test_images = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n","\n","\n","for e, id in enumerate(train_ids):\n","    path = TRAIN_DATA_IMAGES_PATH + id\n","\n","    img = imread(path)[:,:,:IMG_CHANNELS]\n","    images[e] = img\n","\n","    class1 = gradients[id]['class1']\n","    class2 = gradients[id]['class2']\n","    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n","    \n","    for point in class1:\n","        mask = mark_gradient(point[1], point[0], mask, point[2])\n","\n","    for point in class2:\n","        mask = mark_gradient(point[1], point[0], mask, point[2])\n","\n","    masks[e] = mask\n","\n","for e, id in enumerate(test_ids):\n","    path = TEST_DATA_IMAGES_PATH + id\n","    img = imread(path)[:,:,:IMG_CHANNELS]\n","    test_images[e] = img\n","\n","# normalize values 0 - 1\n","masks = masks/255\n","images = images/255\n","test_images = test_images/255\n","\n","print(np.shape(images))\n","print(np.shape(masks))\n","print(np.shape(test_images))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CxkP9S_y8w8B"},"outputs":[],"source":["# SHOW RANDOM IMAGE AND MASK\n","image_x = random.randint(0, len(train_ids)-1)\n","\n","fig = plt.figure(figsize=(PLOT_SIZE, PLOT_SIZE))\n","counterpoint_results = counterpoint(masks[image_x], LOCAL_FILTER, MINIMUM_DISTANCE, TM, images[image_x])\n","\n","plt.subplot(131), imshow(counterpoint_results[2])\n","plt.subplot(132), imshow(np.squeeze(counterpoint_results[1]))\n","plt.subplot(133), imshow(np.squeeze(masks[image_x]))\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jk7Pdh1jWXKB"},"outputs":[],"source":["# BUILD THE MODEL\n","inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n","\n","# encoder\n","c1 = tf.keras.layers.Conv2D(FIRST_CONVS, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n","c1 = tf.keras.layers.Dropout(0.1)(c1)\n","c1 = tf.keras.layers.Conv2D(FIRST_CONVS, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n","p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n","\n","c2 = tf.keras.layers.Conv2D(FIRST_CONVS*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n","c2 = tf.keras.layers.Dropout(0.1)(c2)\n","c2 = tf.keras.layers.Conv2D(FIRST_CONVS*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n","p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n"," \n","c3 = tf.keras.layers.Conv2D(FIRST_CONVS*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n","c3 = tf.keras.layers.Dropout(0.2)(c3)\n","c3 = tf.keras.layers.Conv2D(FIRST_CONVS*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n","p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n"," \n","c4 = tf.keras.layers.Conv2D(FIRST_CONVS*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n","c4 = tf.keras.layers.Dropout(0.2)(c4)\n","c4 = tf.keras.layers.Conv2D(FIRST_CONVS*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n","p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n"," \n","c5 = tf.keras.layers.Conv2D(FIRST_CONVS*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n","c5 = tf.keras.layers.Dropout(0.3)(c5)\n","c5 = tf.keras.layers.Conv2D(FIRST_CONVS*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n","\n","# decoder\n","u6 = tf.keras.layers.Conv2DTranspose(FIRST_CONVS*8, (2, 2), strides=(2, 2), padding='same')(c5)\n","u6 = tf.keras.layers.concatenate([u6, c4])\n","c6 = tf.keras.layers.Conv2D(FIRST_CONVS*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n","c6 = tf.keras.layers.Dropout(0.2)(c6)\n","c6 = tf.keras.layers.Conv2D(FIRST_CONVS*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n"," \n","u7 = tf.keras.layers.Conv2DTranspose(FIRST_CONVS*4, (2, 2), strides=(2, 2), padding='same')(c6)\n","u7 = tf.keras.layers.concatenate([u7, c3])\n","c7 = tf.keras.layers.Conv2D(FIRST_CONVS*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n","c7 = tf.keras.layers.Dropout(0.2)(c7)\n","c7 = tf.keras.layers.Conv2D(FIRST_CONVS*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n"," \n","u8 = tf.keras.layers.Conv2DTranspose(FIRST_CONVS*2, (2, 2), strides=(2, 2), padding='same')(c7)\n","u8 = tf.keras.layers.concatenate([u8, c2])\n","c8 = tf.keras.layers.Conv2D(FIRST_CONVS*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n","c8 = tf.keras.layers.Dropout(0.1)(c8)\n","c8 = tf.keras.layers.Conv2D(FIRST_CONVS*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n"," \n","u9 = tf.keras.layers.Conv2DTranspose(FIRST_CONVS, (2, 2), strides=(2, 2), padding='same')(c8)\n","u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n","c9 = tf.keras.layers.Conv2D(FIRST_CONVS, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n","c9 = tf.keras.layers.Dropout(0.1)(c9)\n","c9 = tf.keras.layers.Conv2D(FIRST_CONVS, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n"," \n","outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n","\n","# compile model and save architecture\n","model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n","opt = keras.optimizers.Adam(learning_rate=LR)\n","model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['binary_crossentropy'])\n","model.save(SAVE_MODEL_PATH)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TF8LHboj5br-"},"outputs":[],"source":["# VALIDATION SPLIT\n","# validation split and augmentation inspired by: https://github.com/bnsreenu/python_for_microscopists/blob/master/219_unet_small_dataset_using_functional_blocks.py\n","X_train, X_test, Y_train, Y_test = train_test_split(images, masks, test_size = VALIDATION_SPLIT, random_state = seed)\n","print(X_train.shape)\n","print(X_test.shape)\n","\n","print(Y_train.shape)\n","print(Y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFsIxFB468YR"},"outputs":[],"source":["# AUGMENTATION\n","img_data_gen_args = dict(rotation_range=5,\n","                         vertical_flip=True,\n","                         #width_shift_range=0.1,\n","                         #height_shift_range=0.1,\n","                         #shear_range=0.15,\n","                         zoom_range=[0.7, 1],\n","                         fill_mode='reflect')\n","                         #preprocessing_function=random_noise)\n","\n","mask_data_gen_args = dict(rotation_range=5,\n","                         vertical_flip=True,\n","                         #width_shift_range=0.1,\n","                         #height_shift_range=0.1,\n","                         #shear_range=0.15,\n","                         zoom_range=[0.7, 1],\n","                         fill_mode='reflect')\n","\n","image_data_generator = ImageDataGenerator(**img_data_gen_args)\n","image_data_generator.fit(X_train, augment=True, seed=seed)\n","\n","image_generator = image_data_generator.flow(X_train, seed=seed, batch_size=16)\n","valid_img_generator = image_data_generator.flow(X_test, seed=seed, batch_size=16)\n","\n","mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n","mask_data_generator.fit(Y_train, augment=True, seed=seed)\n","mask_generator = mask_data_generator.flow(Y_train, seed=seed, batch_size=16)\n","valid_mask_generator = mask_data_generator.flow(Y_test, seed=seed, batch_size=16)\n","\n","def my_image_mask_generator(image_generator, mask_generator):\n","    train_generator = zip(image_generator, mask_generator)\n","    for (img, mask) in train_generator:\n","        yield (img, mask)\n","\n","my_generator = my_image_mask_generator(image_generator, mask_generator)\n","\n","validation_datagen = my_image_mask_generator(valid_img_generator, valid_mask_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2oVAevhxyqJi"},"outputs":[],"source":["# SHOW RANDOM AUGMENTED IMAGE\n","x = image_generator.next()\n","y = mask_generator.next()\n","for i in range(0,1):\n","    fig = plt.figure(figsize=(PLOT_SIZE, PLOT_SIZE))\n","    image = x[i]\n","    mask = y[i]\n","    plt.subplot(1,2,1)\n","    plt.imshow(image)\n","    plt.subplot(1,2,2)\n","    plt.imshow(np.squeeze(mask))\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ML5--jtYWMt7"},"outputs":[],"source":["# SET CHECKPOINTS\n","callbacks = [tf.keras.callbacks.ModelCheckpoint(SAVE_MODEL_PATH, verbose=1, save_best_only=True, save_weights_only=False, save_freq = 'epoch', monitor='val_loss', mode='min')]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"45ChLcQJSS0w"},"outputs":[],"source":["# TRAIN MODEL\n","# set train parametres\n","batch_size = 36\n","steps_per_epoch = 3*(len(X_train))//batch_size\n","print(steps_per_epoch)\n","\n","# train model\n","results = model.fit(my_generator, validation_data=validation_datagen, steps_per_epoch=steps_per_epoch, validation_steps=steps_per_epoch, epochs=500, callbacks=callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysHxGQLqaruP"},"outputs":[],"source":["# LOAD MODEL FOR TRAIN ON A SAME WEIGHTS IN CASE OF GOOGLE COLAB SHUTDOWN\n","model = tf.keras.models.load_model(SAVE_MODEL_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hE-16fPITQ41"},"outputs":[],"source":["# LOAD TRAINED MODEL\n","trained_model = tf.keras.models.load_model(SAVE_MODEL_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H9Bq6fqiWHLz"},"outputs":[],"source":["# TEST TRAINED MODEL ON TRAIN DATA\n","idx = random.randint(0, len(X_train)-2)\n","print('train image: ', idx)\n","\n","fig = plt.figure(figsize=(PLOT_SIZE, PLOT_SIZE))\n","\n","preds_model = trained_model.predict(np.expand_dims(X_train[idx], axis=0))\n","counterpoint_results = counterpoint(preds_model[0], LOCAL_FILTER, MINIMUM_DISTANCE, TM, X_train[idx])\n","\n","# show results\n","plt.subplot(131), imshow(np.squeeze(counterpoint_results[1]))\n","print('found scales:', len(counterpoint_results[0]))\n","\n","# show original mask\n","plt.subplot(132), imshow(np.squeeze(Y_train[idx]))\n","# show original image\n","plt.subplot(133), imshow(X_train[idx])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9arLlLRRdlrQ"},"outputs":[],"source":["# TEST TRAINED MODEL ON TEST DATA\n","random.randint(0, len(X_test)-2)\n","print('test image: ', idx)\n","\n","fig = plt.figure(figsize=(PLOT_SIZE, PLOT_SIZE))\n","\n","preds_model = trained_model.predict(np.expand_dims(X_test[idx], axis=0))\n","counterpoint_results = counterpoint(preds_model[0], LOCAL_FILTER, MINIMUM_DISTANCE, TM, X_test[idx])\n","\n","# show results\n","plt.subplot(131), imshow(np.squeeze(counterpoint_results[1]))\n","print('found scales:', len(counterpoint_results[0]))\n","\n","# show original image\n","plt.subplot(122), imshow(X_test[idx])\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPbB4bvRcbGadiv94uSOL++","collapsed_sections":[],"mount_file_id":"1k3gc1nAQ-x1Hzj0TIUKltdoxqnIVNuMb","name":"unet_jupyter_train.ipynb","provenance":[{"file_id":"1k3gc1nAQ-x1Hzj0TIUKltdoxqnIVNuMb","timestamp":1630683108666}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
